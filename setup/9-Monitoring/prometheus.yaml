apiVersion: v1
kind: ServiceAccount
metadata:
  name: monitoring
  namespace: infra
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: monitoring
subjects:
  - kind: ServiceAccount
    name: monitoring
    namespace: infra
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-server-conf
  labels:
    name: prometheus-server-conf
  namespace: infra
data:
  prometheus.yml: |-
    global:
      scrape_interval: 60s
      evaluation_interval: 60s

    rule_files:
      - "/etc/prometheus-rules/*.rules"

    alerting:
      alertmanagers:
        - scheme: http
          path_prefix: /
          static_configs:
            - targets: ['alertmanager:9093']

    scrape_configs:
      # - job_name: prometheus
      #   static_configs:
      #     - targets: ['localhost:9090']

      - job_name: traefik
        basic_auth:
          username: admin
          password: welcomewelcome1 # FIXME: Figure out how to get this from configmap
        static_configs:
          - targets: ['traefik-ingress-controller-dashboard-service:8080']

      - job_name: nodes
        static_configs:
          - targets:
            - '10.0.0.1:9100'
            - '10.0.0.2:9100'
            - '10.0.0.3:9100'
            - '10.0.0.4:9100'

      - job_name: loki
        static_configs:
          - targets: ['loki:3100']

      - job_name: kubernetes-apiservers
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            regex: default;kubernetes;https
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
              - __meta_kubernetes_endpoint_port_name
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-nodes-kubelet
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-nodes-cadvisor
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
        metric_relabel_configs:
          - action: replace
            source_labels: [id]
            regex: '^/machine\.slice/machine-rkt\\x2d([^\\]+)\\.+/([^/]+)\.service$'
            target_label: rkt_container_name
            replacement: '${2}-${1}'
          - action: replace
            source_labels: [id]
            regex: '^/system\.slice/(.+)\.service$'
            target_label: systemd_service_name
            replacement: '${1}'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-service-endpoints
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            regex: true
            source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          - action: replace
            regex: (https?)
            source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - action: replace
            source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_name

      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - action: keep
            regex: true
            source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - action: replace
            regex: (.+)
            source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            target_label: __metrics_path__
          - action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]
            target_label: kubernetes_pod_name

      - job_name: kubernetes-services
        kubernetes_sd_configs:
          - role: service
        metrics_path: /probe
        params:
          module:
            - http_2xx
        relabel_configs:
          - action: keep
            regex: true
            source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
          - source_labels: [__address__]
            target_label: __param_target
          - replacement: blackbox-exporter:9115
            target_label: __address__
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_name

      - job_name: kubernetes-ingresses
        kubernetes_sd_configs:
          - role: ingress
        metrics_path: /probe
        params:
          module:
            - http_2xx
        relabel_configs:
          - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
            regex: (.+);(.+);(.+)
            replacement: ${1}://${2}${3}
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox-exporter:9115
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_ingress_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_ingress_name]
            target_label: kubernetes_name

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  labels:
    name: prometheus-rules
  namespace: infra
data:
  alert.rules: |-
    groups:
      - name: Deployment
        rules:
        - alert: Deployment at 0 Replicas
          annotations:
            summary: Deployment {{$labels.deployment}} in {{$labels.namespace}} namespace currently has no pods running
          expr: |
            sum(kube_deployment_status_replicas{pod_template_hash=""}) by (deployment,namespace)  < 1
          for: 1m
          labels:
            team: devops

        - alert: HPA Scaling Limited
          annotations:
            summary: HPA named {{$labels.hpa}} in {{$labels.namespace}} namespace has reached scaling limit
          expr: |
            (sum(kube_hpa_status_condition{condition="ScalingLimited",status="true"}) by (hpa,namespace)) == 1
          for: 1m
          labels:
            team: devops

        - alert: HPA at MaxCapacity
          annotations:
            summary: HPA named {{$labels.hpa}} in {{$labels.namespace}} namespace is running at Max Capacity
          expr: |
            ((sum(kube_hpa_spec_max_replicas) by (hpa,namespace)) - (sum(kube_hpa_status_current_replicas) by (hpa,namespace))) == 0
          for: 1m
          labels:
            team: devops

      - name: Pods
        rules:
        - alert: Container restarted
          annotations:
            summary: Container named {{$labels.container}} in {{$labels.pod}} in {{$labels.namespace}} namespace was restarted
          expr: |
            sum(increase(kube_pod_container_status_restarts_total{namespace!="kube-system",pod_template_hash=""}[1m])) by (pod,namespace,container) > 0
          for: 0m
          labels:
            team: dev

        - alert: High Memory Usage of Container
          annotations:
            summary: Container named {{$labels.container}} in {{$labels.pod}} in {{$labels.namespace}} namespace is using more than 75% of Memory Limit
          expr: |
            ((( sum(container_memory_usage_bytes{image!="",container_name!="POD", namespace!="kube-system"}) by (namespace,container_name,pod_name)  / sum(container_spec_memory_limit_bytes{image!="",container_name!="POD",namespace!="kube-system"}) by (namespace,container_name,pod_name) ) * 100 ) < +Inf ) > 75
          for: 5m
          labels:
            team: dev

        - alert: High CPU Usage of Container
          annotations:
            summary: Container named {{$labels.container}} in {{$labels.pod}} in {{$labels.namespace}} namespace is using more than 75% of CPU Limit
          expr: |
            ((sum(irate(container_cpu_usage_seconds_total{image!="",container_name!="POD", namespace!="kube-system"}[30s])) by (namespace,container_name,pod_name) / sum(container_spec_cpu_quota{image!="",container_name!="POD", namespace!="kube-system"} / container_spec_cpu_period{image!="",container_name!="POD", namespace!="kube-system"}) by (namespace,container_name,pod_name) ) * 100)  > 75
          for: 5m
          labels:
            team: dev

      - name: Nodes
        rules:
        - alert: High Node Memory Usage
          annotations:
            summary: Node {{$labels.kubernetes_io_hostname}} has more than 80% memory used.
          expr: |
            (sum (container_memory_working_set_bytes{id="/",container_name!="POD"}) by (kubernetes_io_hostname) / sum (machine_memory_bytes{}) by (kubernetes_io_hostname) * 100) > 80
          for: 5m
          labels:
            team: devops

        - alert: High Node CPU Usage
          annotations:
            summary: Node {{$labels.kubernetes_io_hostname}} has more than 80% allocatable CPU used.
          expr: |
            (sum(rate(container_cpu_usage_seconds_total{id="/", container_name!="POD"}[1m])) by (kubernetes_io_hostname) / sum(machine_cpu_cores) by (kubernetes_io_hostname)  * 100) > 80
          for: 5m
          labels:
            team: devops

        - alert: High Node Disk Usage
          annotations:
            summary: Node {{$labels.kubernetes_io_hostname}} has more than 85% disk used.
          expr: |
            (sum(container_fs_usage_bytes{device=~"^/dev/([sv]d[a-z][1-9]|root)$",id="/",container_name!="POD"}) by (kubernetes_io_hostname) / sum(container_fs_limit_bytes{container_name!="POD",device=~"^/dev/([sv]d[a-z][1-9]|root)$",id="/"}) by (kubernetes_io_hostname)) * 100 > 85
          for: 5m
          labels:
            team: devops
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-claim
  namespace: infra
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 25Gi
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: prometheus
  namespace: infra
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus-server
    spec:
      serviceAccountName: monitoring
      initContainers:
        - name: init-chown-data
          image: busybox:latest
          imagePullPolicy: IfNotPresent
          # 65534 is the nobody user that prometheus uses.
          command: ["chown", "-R", "65534:65534", "/prometheus/"]
          volumeMounts:
            - name: prometheus-storage-volume
              mountPath: /prometheus/
      containers:
        - name: prometheus
          image: prom/prometheus:master
          args:
            - --storage.tsdb.retention.time=360h
            - --config.file=/etc/prometheus/prometheus.yml
            - --storage.tsdb.path=/prometheus/
            - --web.enable-lifecycle
            - --storage.tsdb.no-lockfile
            - --web.enable-admin-api
            - --web.external-url=http://prometheus.cluster.local
          ports:
            - name: prometheus
              containerPort: 9090
          volumeMounts:
            - name: prometheus-config-volume
              mountPath: /etc/prometheus/
            - name: prometheus-storage-volume
              mountPath: /prometheus/
            - name: rules-volume
              mountPath: /etc/prometheus-rules
        # - name: prometheus-reload
        #   image: carlosedp/configmap-reload:v0.2.2-arm
        #   args:
        #     - --volume-dir=/etc/config
        #     - --volume-dir=/etc/prometheus-rules
        #     - --webhook-url=http://127.0.0.1:9090/-/reload
        #   volumeMounts:
        #     - name: prometheus-config-volume
        #       mountPath: /etc/config
        #     - name: rules-volume
        #       mountPath: /etc/prometheus-rules
      volumes:
        - name: prometheus-config-volume
          configMap:
            defaultMode: 420
            name: prometheus-server-conf
        - name: prometheus-storage-volume
          persistentVolumeClaim:
            claimName: prometheus-claim
        - name: rules-volume
          configMap:
            name: prometheus-rules

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: infra
  labels:
    name: prometheus
  annotations:
    prometheus.io/scrape: "true"
spec:
  selector:
    app: prometheus-server
  ports:
    - name: prometheus
      port: 8080
      targetPort: prometheus
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: prometheus
  namespace: infra
  annotations:
    kubernetes.io/ingress.class: traefik
    ingress.kubernetes.io/auth-type: basic
    ingress.kubernetes.io/auth-secret: dashboards-auth
    forecastle.stakater.com/expose: "true"
    forecastle.stakater.com/group: "Tools"
    forecastle.stakater.com/icon: "https://raw.githubusercontent.com/stakater/ForecastleIcons/master/prometheus.png"
spec:
  rules:
    - host: prometheus.cluster.local
      http:
        paths:
          - path: /
            backend:
              serviceName: prometheus
              servicePort: 8080